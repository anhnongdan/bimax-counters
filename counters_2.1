#!/usr/bin/python
import multiprocessing
import os
import time


from threading import Thread
from Queue import Queue
import sys, time
import logging
logging.basicConfig(filename='/data/logs/counters.log',level=logging.DEBUG)

from nginx_log_parser import NginxLogParser
from dateutil.parser import parse

from datetime import datetime, timedelta
from pytz import timezone, utc
from pytz.tzinfo import StaticTzInfo

class OffsetTime(StaticTzInfo):
    def __init__(self, offset):
        """A dumb timezone based on offset such as +0530, -0600, etc.
        """
        hours = int(offset[:3])
        minutes = int(offset[0] + offset[3:])
        self._utcoffset = timedelta(hours=hours, minutes=minutes)

def load_datetime(value, format):
    if format.endswith('%z'):
        format = format[:-2]
        offset = value[-5:]
        value = value[:-5]
        return OffsetTime(offset).localize(datetime.strptime(value, format))

    return datetime.strptime(value, format)

def dump_datetime(value, format):
    return value.strftime(format)
#vnpt-hni-14 - - [meta sequenceId="49552677"] nginx:
#parser = NginxLogParser('$request_time $remote_addr $sent_http_x_cache [$time_local] ' + \
parser = NginxLogParser('$remote_host - - [$seq_id] nginx: $request_time $remote_addr $sent_http_x_cache [$time_local] ' + \
			'"$request" $http_host $status $body_bytes_sent ' + \
			'"$http_referer" "$http_user_agent" "$http_range"')
import redis
#rd = redis.Redis(unix_socket_path='/tmp/redis.sock', db=0)

NTIME = 1
#GLOBALLOCK = multiprocessing.Lock()

num_worker_process = 128
num_worker_main = 64
# t_timeout = 10
tcount = 100000
tqueue = []

def check_time1(atime):
    #return True
    cur = datetime.now()
    min5 = cur.minute - (cur.minute % 5);
    cur5 = cur.replace(minute=min5)
    nn = cur5.strftime("5:%Y%m%d%H%M%z+0700")

    if atime != nn:
        return False
    return True

def check_time(tqueue1):
    #return True
    cur = datetime.now()
    min5 = cur.minute - (cur.minute % 5);
    cur5 = cur.replace(minute=min5)
    nn = cur5.strftime("5:%Y%m%d%H%M%z+0700")
    tt = tqueue1[0]
    if tt['name'] != nn:
        return False
    return True

def flush_queue(the_queue, tqueue):
    ll = len(tqueue)
    if ll > 0 and check_time(tqueue):
        logging.info("flush:%d" % ll)
        the_queue.put(tqueue[:])
        tqueue[:] = []
    else:
        tqueue[:] = []

import uuid

def worker(myqueue):
    id=uuid.uuid4()

    cache_val = {}
    logging.info("process start:%s" % id)
    rd = redis.Redis(unix_socket_path='/tmp/redis.sock', db=0)
    tqueue1 = []
    oldut = 0
    while True:
        try:
            tqueue1 = myqueue.get()
            n = len(tqueue1)
            if n == 0:
                continue
            ss = len(tqueue1)
            cur = datetime.now()
            ut = int(time.mktime(cur.timetuple()))

            if not check_time(tqueue1):
                #logging.info("flush: onprocess")
                continue

            send = False
            if ut - oldut > NTIME:
                oldut = ut
                send = True

            for tval in tqueue1:
                kk = "%s###%s" %(tval['type'], tval['name'])
                if kk in cache_val:
                    cache_val[kk] = cache_val[kk] + float(tval['val'])
                else:
                    cache_val[kk] = float(tval['val'])
            if send:
                logging.info("redis:%d" % len(cache_val))
                pp = rd.pipeline()
                for kk in cache_val:
                    vv = float(cache_val[kk])
                    type,name = kk.split("###")
                    pp.hincrbyfloat(type, name, vv)
                pp.execute()
                cache_val = {}
        except Exception, err:
            logging.info(err)
            continue




def workerMain(mainQueue, the_queue):
    id=uuid.uuid4()
    logging.info("main start:%s" % id)
    cur = datetime.now()
    utime = int(time.mktime(cur.timetuple()))
    while True:
        try:
            message = mainQueue.get()
            pp = parser.parse_line(message)
            if not pp:
                continue
            #logging.info(pp)
            rhost = pp["remote_host"]
            if pp['http_host']:
                cat = pp['http_host']
            else:
                cat = category

            if pp['time_local'] is None or pp['status'] is None or pp['body_bytes_sent'] is None or pp['request_time'] is None:
                continue

            cur = load_datetime(pp['time_local'], '%d/%b/%Y:%H:%M:%S %z')
            localtime = dump_datetime(cur, "%Y%m%d%H%M%z")
            min5 = cur.minute - (cur.minute % 5);
            cur5 = cur.replace(minute=min5)
            localtime5 = dump_datetime(cur5, "5:%Y%m%d%H%M%z")
            #if not check_time1(localtime5):
#                logging.info("flush: onreal:%s" % localtime5)
            #    continue

            tqueue.append({
                "type": "rhost_request_count_%s|%s" % (str(pp["status"]), str(rhost)),
                "name":localtime5,
                "val":1})
            tqueue.append({
                "type": "request_count_%s|%s" % (str(pp["status"]), str(cat)),
                "name":localtime5,
                "val":1})
            if pp['status'] == '200' or  pp['status'] == '206':
                tqueue.append({"type": "rhost_body_bytes_sent" + "|"  + rhost, "name": localtime5, "val":pp["body_bytes_sent"]})
                tqueue.append({"type": "body_bytes_sent" + "|"  + cat , "name": localtime5, "val":pp["body_bytes_sent"]})
                tqueue.append({"type": "rhost_request_time" + "|"  + rhost, "name":localtime5, "val":pp["request_time"]})
                tqueue.append({"type": "request_time" + "|"  + cat , "name":localtime5, "val":pp["request_time"]})


                if float(pp["request_time"]) > 0.0000001:
                    speed_request = float(pp["body_bytes_sent"]) / float(pp["request_time"])
                    tqueue.append({"type": "speed_request" + "|"  + cat , "name": localtime5, "val": speed_request})
                    tqueue.append({"type": "rhost_speed_request" + "|"  + rhost, "name": localtime5, "val": speed_request})
                    tqueue.append({
                        "type": "rhost_request_count_2xx|%s" % str(rhost),
                        "name":localtime5,
                        "val":1})
                    tqueue.append({
                        "type": "request_count_2xx|%s" % str(cat),
                        "name":localtime5,
                        "val":1})

            cur1 = datetime.now()
            utime1 = int(time.mktime(cur1.timetuple()))
            if utime1 - utime > NTIME:
                utime = utime1
                flush_queue(the_queue, tqueue)
                continue

            if len(tqueue) >= tcount:
                utime = utime1
                flush_queue(the_queue, tqueue)
                continue
        except Exception, err:
            logging.info(err)
            continue


the_queue = multiprocessing.Queue()
mainQueue = multiprocessing.Queue()
the_pool = multiprocessing.Pool(num_worker_process, worker,(the_queue,))
mainPool = multiprocessing.Pool(num_worker_main, workerMain,(mainQueue, the_queue,))



while True:
    try:
        message = sys.stdin.readline()
        if not message:
            continue
	#logging.info(message)
        mainQueue.put_nowait(message)
    except Exception, err:
        logging.info(err)
        continue
