#!/usr/bin/python
import multiprocessing
import os
import time

from threading import Thread
from Queue import Queue
import sys, time
import logging
logging.basicConfig(filename='/tmp/counters.log',level=logging.DEBUG)

from nginx_log_parser import NginxLogParser
from dateutil.parser import parse

from datetime import datetime, timedelta
from pytz import timezone, utc
from pytz.tzinfo import StaticTzInfo

class OffsetTime(StaticTzInfo):
    def __init__(self, offset):
        """A dumb timezone based on offset such as +0530, -0600, etc.
        """
        hours = int(offset[:3])
        minutes = int(offset[0] + offset[3:])
        self._utcoffset = timedelta(hours=hours, minutes=minutes)

def load_datetime(value, format):
    if format.endswith('%z'):
        format = format[:-2]
        offset = value[-5:]
        value = value[:-5]
        return OffsetTime(offset).localize(datetime.strptime(value, format))

    return datetime.strptime(value, format)

def dump_datetime(value, format):
    return value.strftime(format)
#vnpt-hni-14 - - [meta sequenceId="49552677"] nginx:
#parser = NginxLogParser('$request_time $remote_addr $sent_http_x_cache [$time_local] ' + \
parser = NginxLogParser('$remote_host - - [$seq_id] nginx: $request_time $remote_addr $sent_http_x_cache [$time_local] ' + \
			'"$request" $http_host $status $body_bytes_sent ' + \
			'"$http_referer" "$http_user_agent" "$http_range"')
import redis



#q_msg = Queue()
q_msg = multiprocessing.Queue()
#q_counter = Queue()
#q_flush = Queue()

def check_time1(atime):
    cur = datetime.now()
    min5 = cur.minute - (cur.minute % 5);
    cur5 = cur.replace(minute=min5)
    nn = cur5.strftime("5:%Y%m%d%H%M%z+0700")

    if atime != nn:
        return False
    return True

def do_flush(rd, cache_val):
    pp = rd.pipeline()
    for kk in cache_val:
         vv = float(cache_val[kk])
         type,name = kk.split("###")
         if check_time1(name):
             pp.hincrbyfloat(type, name, vv)
    pp.execute()

def do_count(cache_val, tqueue):
    for tval in tqueue:
        kk = "%s###%s" %(tval['type'], tval['name'])
        if kk in cache_val:
            cache_val[kk] = cache_val[kk] + float(tval['val'])
        else:
            cache_val[kk] = float(tval['val'])

def do_count1(rd, tqueue):
    cache_val = {}
    for tval in tqueue:
        kk = "%s###%s" %(tval['type'], tval['name'])
        if kk in cache_val:
            cache_val[kk] = cache_val[kk] + float(tval['val'])
        else:
            cache_val[kk] = float(tval['val'])
    logging.info("short:%d" % len(cache_val))
    do_flush(rd, cache_val)


def workerFlush(id, mainQueue, otherQueue):
    rd = redis.Redis(unix_socket_path='/tmp/redis.sock', db=0)
    logging.info("workerFlush:%s" % id)
    while True:
        try:
            #if mainQueue.empty():
            #    continue
            message = mainQueue.get()
            #message = mainQueue.get_nowait()
            if not message:
                continue
            logging.info("flush:get:%d" % len(message))
            mainQueue.task_done()
            do_flush(rd, message)

        except Exception, err:
            pass

def workerCounter(id, mainQueue, otherQueue):
    NTIME = 1
    logging.info("workerCount:%s" % id)
    cur = datetime.now()
    utime = int(time.mktime(cur.timetuple()))
    tqueue = {}
    while True:
        try:
            #if mainQueue.empty():
            #    continue
            message = mainQueue.get()
            #message = mainQueue.get_nowait()
            if not message:
                continue 
            logging.info("counter:get:%d" % len(message))
            mainQueue.task_done()
            cur1 = datetime.now()
            utime1 = int(time.mktime(cur1.timetuple()))
            do_count(tqueue, message)
            if (utime1 - utime) > NTIME:
                utime = utime1
                logging.info("counter:flush:%d" % len(tqueue))
                qtmp = tqueue.copy()
                tqueue = {}
                otherQueue.put(qtmp)
                continue
        except Exception, err:
            pass



#NTIME = 3
#TCOUNT = 100
def workerMain(id, mainQueue):
    rd = redis.Redis(unix_socket_path='/tmp/redis.sock', db=0)
    NTIME = 1
    logging.info("workerMain:%s" % id)
    cur = datetime.now()
    utime = int(time.mktime(cur.timetuple()))
    tqueue = []
    while True:
        try:
            if mainQueue.empty():
                continue
            #message = mainQueue.get()
            message = mainQueue.get_nowait()
            if not message:
                continue
            pp = parser.parse_line(message)
            if not pp:
                continue
            rhost = pp["remote_host"]
            if pp['http_host']:
                cat = pp['http_host']
            else:
                cat = category

            if pp['time_local'] is None or pp['status'] is None or pp['body_bytes_sent'] is None or pp['request_time'] is None:
                continue

            cur = load_datetime(pp['time_local'], '%d/%b/%Y:%H:%M:%S %z')
            localtime = dump_datetime(cur, "%Y%m%d%H%M%z")
            min5 = cur.minute - (cur.minute % 5);
            cur5 = cur.replace(minute=min5)
            localtime5 = dump_datetime(cur5, "5:%Y%m%d%H%M%z")
            if not check_time1(localtime5):
                continue


            tqueue.append({
                "type": "rhost_request_count_%s|%s" % (str(pp["status"]), str(rhost)),
                "name":localtime5,
                "val":1})
            tqueue.append({
                "type": "request_count_%s|%s" % (str(pp["status"]), str(cat)),
                "name":localtime5,
                "val":1})
            if pp['status'] == '200' or  pp['status'] == '206':
                tqueue.append({"type": "rhost_body_bytes_sent" + "|"  + rhost, "name": localtime5, "val":pp["body_bytes_sent"]})
                tqueue.append({"type": "body_bytes_sent" + "|"  + cat , "name": localtime5, "val":pp["body_bytes_sent"]})
                tqueue.append({"type": "rhost_request_time" + "|"  + rhost, "name":localtime5, "val":pp["request_time"]})
                tqueue.append({"type": "request_time" + "|"  + cat , "name":localtime5, "val":pp["request_time"]})


                if float(pp["request_time"]) > 0.0000001:
                    speed_request = float(pp["body_bytes_sent"]) / float(pp["request_time"])
                    tqueue.append({"type": "speed_request" + "|"  + cat , "name": localtime5, "val": speed_request})
                    tqueue.append({"type": "rhost_speed_request" + "|"  + rhost, "name": localtime5, "val": speed_request})
                    tqueue.append({
                        "type": "rhost_request_count_2xx|%s" % str(rhost),
                        "name":localtime5,
                        "val":1})
                    tqueue.append({
                        "type": "request_count_2xx|%s" % str(cat),
                        "name":localtime5,
                        "val":1})

            cur1 = datetime.now()
            utime1 = int(time.mktime(cur1.timetuple()))
            if (utime1 - utime) > NTIME:
                utime = utime1
                qtmp = tqueue[:]
                tqueue[:] = []
                logging.info("main:flush:%d" % len(qtmp))
		do_count1(rd, qtmp)
            mainQueue.task_done()
        except Exception, err:
            pass 


POOL = []
POOL_INIT = 1
POOL_COUNTER = []
POOL_COUNTER_INIT = 1
POOL_FLUSH = []
POOL_FLUSH_INIT = 1

def create_thread(pool, func, q):
    i = len(pool) + 1
    #t = Thread(target=func, name='q_msg_%d' % i,args=(i, q))
    t = multiprocessing.Process(target=func, name='q_msg_%d' % i,args=(i, q))
    pool.append(t)
    t.daemon = True
    t.start()

for i in range(POOL_INIT):
    create_thread(POOL, workerMain, q_msg )
#for i in range(POOL_COUNTER_INIT):
#    create_thread(POOL_COUNTER, workerCounter, q_counter, q_flush)
#for i in range(POOL_FLUSH_INIT):
#    create_thread(POOL_FLUSH, workerFlush, q_flush, None)


def check_counter(POOL, q_msg ):
    while True:
        time.sleep(3)
        qs = q_msg.qsize()
#        qs1 = q_counter.qsize()
#        qs2 = q_flush.qsize()
        if qs > 10:
            create_thread(POOL, workerMain, q_msg)
#        if qs1 > 3:
#           create_thread(POOL_COUNTER, workerCounter, q_counter, q_flush)
#        if qs2 > 3:
#           create_thread(POOL_FLUSH, workerFlush, q_flush, None)

        logging.info("qsize:%d nworker:%d" % (qs, len(POOL)))
#        logging.info("q_counter_size:%d nworker:%d" % (qs1, len(POOL_COUNTER)))
#        logging.info("q_flush_size:%d nworker:%d" % (qs2, len(POOL_FLUSH)))
t = Thread(target=check_counter, name='' ,args=(POOL, q_msg ))
#t = Thread(target=check_counter, name='' ,args=(POOL, POOL_COUNTER, POOL_FLUSH, q_msg, q_counter, q_flush))
t.daemon = True
t.start()


while True:
    try:
        message = sys.stdin.readline()
        if not message:
            continue
        message = message.replace('""', '"-"')
        #q_msg.put(message)
        q_msg.put_nowait(message)

    except Exception, err:
        #logging.info(err)
        pass
t.join()
